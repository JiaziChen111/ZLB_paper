\documentclass[12pt,reqno]{article}
\usepackage[utf8x]{inputenc}
\usepackage{graphicx}
\usepackage[table]{xcolor}
\graphicspath{ {figures/} }
\usepackage[margin=0.9in]{geometry}

\usepackage{amssymb}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{pdflscape}
\usepackage{natbib}
\usepackage{verbatim}
\usepackage{gensymb}
\usepackage{comment}
\usepackage{bm}
\usepackage{changepage}
%\usepackage{amsart}
\usepackage{lscape}
\usepackage{soul}
\usepackage{float}
\usepackage{rotating}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage[color]{changebar}
\linespread{.5}
\numberwithin{equation}{section}
\usepackage{appendix}
\usepackage{authblk}
\usepackage{hyperref}
\usepackage[most]{tcolorbox}



\hypersetup{colorlinks,allcolors=blue}

\title{Restricted Perceptions and the Zero Lower Bound Episode \footnote{The research project is financially supported by the National Bank of Belgium under \textit{the Research Programme for Young Researchers}. The views expressed in this paper are those of the author and do not necessarily reflect the views 
of the National Bank of Belgium or any other institution to which the author is affiliated.}}
\author{Tolga Ozden\footnote{Affiliation: University of Amsterdam}, Raf Wouters\footnote{Affiliation: National Bank of Belgium}}
\begin{document}

\maketitle

%\begin{abstract}
\subsection*{Extended Abstract}

In recent years, two general classes of time-varying DSGE models that have gained attraction in the literature: The first one 
is the class of Markov-switching models that allow for time-variation in the structural system parameters, which offer a tractable way of studying 
regime shifts. The second one is adaptive expectation models that allow agents' beliefs to deviate from the underlying Rational Expectations
Equilibrium (REE) and instead vary over time based on historical data. In this paper, we bring these two classes of models together and construct a framework that allows for the estimation of Markov-switching DSGE models under adaptive expectations.
In particular, we consider scenarios where the agents' perceived law of motion (PLM) is based on small forecasting rules that do not take
into account the regime shifts in the underlying system. We build on this idea to estimate DSGE models under adaptive expectations during 
the recent zero lower bound (ZLB) episode that started with the onset of the 2007-08 crisis.

We start by considering the E-stability principle in Markov-switching models: An Equilibrium is said to be E-stable 
if the agents can learn the underlying equilibrium by starting from an arbitrary point and updating their beliefs based on simple 
recursive algorithms, such as recursive least squares. If the PLM coincides with the closed-form MSV solution, then the system will 
converge to the underlying REE. However, the underlying equilibrium does not coincide with the REE whenever agents' PLM are misspecified.
In such scenarios, the resulting misspecification equilibrium is called a Restricted Perceptions Equilibrium (RPE) in general. We show the E-stability
of the underlying RPE in two cases:
(i) The PLM coincides with the closed-form MSV solution, but the regime shifts are unknown to the agent. 
(ii) The PLM is based on a parsimonious backward-looking AR(1) rule.

Our results show that, in both cases, there is an E-stable RPE that deviates from the underlying REE. Furthermore, the E-stability of 
these equilibria holds even if one of the underlying Markov regimes is E-unstable, as long as the exit probability from the E-unstable
regime is sufficiently large. In such cases, the system is characterized by erratic behaviour during the unstable regime, while reverting
back to its stable behaviour during the stable regime. We denote this as the \textbf{long-run E-stability principle.} \\

Next we turn to estimation of our class of DSGE models: A popular method in the state-space Markov-switching literature is the Kim \& Nelson (1999) 
filter, which is based on a "collapsing" approximation to make the models tractable. We extend this filter to accommodate adaptive expectations,
and consider the Bayesian estimation of two standard DSGE models: The first one is the 3-equation NKPC model along the lines of  Woodford (2003), which 
is too simplistic for any actual policy analysis, but provides a good starting point for exposing our main results. The second one is the more complex Smets-Wouters (2007)
model, which has become very popular among central banks and policy makers during the last decade. Based on our preliminary estimations, 
our results can be summarized as follows: The Markov-switching adaptive expectation models are able to outperform the REE benchmark in all 
cases, and the Regime-switching REE model in some cases. Furthermore, we observe important differences in the impulse response and shock
propagation structure of the models under consideration. Particularly, a financial shock of the same size (which can be thought of as the
financial crisis of 2007-08) typically has a longer lasting impact under adaptive learning, which suggests that Rational Expectations models
may severely underestimate the crisis' impact and the system's vulnerability to another shock during the Zero lower bound episode. \\

%\end{abstract}

\vspace{3 mm}

\noindent
\textit{JEL Classification:} E37; E65; C11; C32 . \\


\vspace{3 mm}

\noindent
\textit{Keywords:} Adaptive Learning; Markov-Switching;Bayesian Estimation of DSGE Models; Zero Lower Bound. 


%\maketitle

%\section*{Preliminaries}

\begin{comment}
Consider the baseline NKPC: \\

$$
\begin{cases} 
x_t = E_t x_{t+1}  -\frac{1}{\tau}(r_t - E_t \pi_{t+1})+ \epsilon_{x,t} \\
\pi_t = \beta E_t \pi_{t+1} + \gamma x_t + \epsilon_{\pi,t} \\
r_t = max\{ 0, \rho r_{t-1} +(1-\rho) (\phi_x x_t + \phi_{\pi} \pi_t) + \eta_{r,t}\} \\
\epsilon_{y,t} = \rho_y \epsilon_{y,t-1} + \eta_{y,t} \\ 
\epsilon_{\pi,t} = \rho_{\pi} \epsilon_{\pi,t-1} + \eta_{\pi,t} \\
\end{cases} 
$$

\noindent
Monetary policy rule can be re-written as follows: \\

$r_t= \begin{cases} \textrm{0 if ZLB binding,} \\  \rho r_{t-1} +(1-\rho) (\phi_x x_t + \phi_{\pi} \pi_t) + \eta_{r,t} \textrm{\hspace{3 mm} otherwise.}    \end{cases}$ \\

\vspace{5 mm}
\noindent
Denoting by $s_t$ the monetary policy regime, we then obtain the following generic form: \\


\begin{equation}
\begin{cases}
A(r_t) X_t = B(r_t) X_{t-1} + C(r_t) E_{t} X_{t+1} D(r_t) \epsilon_t, \\

E_t X_{t+1} = \alpha_t + \beta_t^2 (X_{t-1} - \alpha_t)  \\

Y_t =E(r_t) +  F(r_t) X_t + H(r_t). \\ 
\end{cases}
\end{equation}

\vspace{10 mm}
\noindent
Beliefs are assumed as a univariate AR(1) rule for the time being, but can be generalized to any other PLM. The system can then be re-written as: \\

\begin{equation}
\begin{cases} 
X_t = \gamma_{2,t}(r_t) + \gamma_{1,t}(r_t) X_{t-1} + \gamma_3(r_t) \epsilon_t, \\

\gamma_{1,t} = A(r_t)^{-1} (B(r_t)+ C(r_t) \beta_t^2),  \\

\gamma_{2,t} = A(r_t)^{-1}C(r_t)(I-\beta_t^2) \alpha_t \\

\gamma_3 = A(r_t)^{-1} D(r_t). \\
\end{cases}
\end{equation}

\newpage
\textbf{\underline{Filtering:}} \\

\vspace{5 mm}
\noindent
$\hat{S}_{1|1}, \hat{P}_{1|1}, \alpha_1, \beta_1 $, and  \\
$\gamma_{1,1}(r_t)= A(r_t)^{-1}(B(r_t)+C(r_t) \beta_1^2), \gamma_{2,1}(r_t) A(r_t)^{-1}C(r_t)(I - \beta_1^2)\alpha_1, \gamma_{3,1}(r_t)=A(r_t)^{-1}D(r_t) $ are given.\\
\begin{equation}
$$
FOR $t=[2:T]$ \\

\hspace{5 mm}     FOR $r_t = [1: R]$\\

\vspace{3 mm}
\noindent
\small{\underline{Update the beliefs \& system matrices:}} \\

\vspace{3 mm}
\noindent
$(\alpha_t, \beta_t) = update(\hat{S}_{t-1|t-1},\alpha_{t-1},\beta_{t-1})$ (according to PLM) \\
$\gamma_{1,t}(r_t)= A(r_t)^{-1}(B(r_t)+C(r_t) \beta_t^2), \\
\gamma_{2,t}(r_t) A(r_t)^{-1}C(r_t)(I - \beta_t^2)\alpha_t,\\
 \gamma_{3,t}(r_t)=A(r_t)^{-1}D(r_t) $.\

\vspace{3 mm}
\noindent
\small{\underline{Forecasting:}} \\

\vspace{3 mm}
\noindent
$S_{t|t-1}(r_t)=\gamma_1(r_t) \hat{S}_{t-1|t-1} + \gamma_2(r_t);$ \\
$P_{t|t-1}(r_t) = \gamma_1(r_t) \hat{P}_{t-1|t-1} \gamma_1(r_t)^{T}+\gamma_3(r_t) \Sigma(r_t) \gamma_3(r_t)^{T}$;\\

\vspace{3 mm}

\noindent
\small{\underline{Forecast errors \& error variances:}} \\
\vspace{3 mm}

\noindent
$v(r_t)=y_t-F(r_t)S_{t|t-1}(r_t);$\\
$Fe(r_t)=F(r_t) P_{t|t-1}F(r_t)^{T}+H;$\\
\vspace{3 mm}

\noindent
\small{\underline{Marginal Likelihoods:}} \\

\vspace{3 mm}

\noindent
$ml_t(r_t)= -\frac{1}{2}L \hspace{2 mm} log(2 \pi) -\frac{1}{2} log(| \Sigma|)-\frac{1}{2} v(r_t)^{T}\Sigma(r_t)^{-1}v(r_t);$\\
\vspace{3 mm}

\noindent
\small{\underline{Kalman gain:}} \\

\vspace{3 mm}

\noindent
$K_t(r_t)=P_{t|t-1}(r_t)F(r_t)^{T}(F(r_t) P_{t|t-1}(r_t)F(r_t)^{T})^{-1};$\\
\vspace{3 mm}

\noindent
\small{\underline{Updating:}} \\

\vspace{3 mm}

\noindent
$S_{t|t}(r_t)=S_{t|t-1}(r_t)+K_t(r_t)v(r_t);$\\
$P_{t|t})r_t)=P_{t|t-1}(r_t)-K_t(r_t)(F(r_t)P_{t|t-1}(r_t));$\\

\vspace{5 mm}
\hspace{5 mm}    END\\ 

\vspace{5 mm}
\noindent
$s(r_t)= \begin{cases} \textrm{1 if  } r_t= argmax_{\hat{r}_t }\hspace{3 mm}  ml_t(\hat{r}_t),  \\ \textrm{0 otherwise.} \end{cases}$ \\

\vspace{3 mm}

\noindent
\small{\underline{Collapsing:}} \\

\vspace{3 mm}

\noindent
$\hat{S}_{t|t}= \sum_{r_t}^R s(r_t) S_{t|t}(r_t);$\\
$\hat{P}_{t|t}=\sum_{r_t}^R s(r_t) P_{t|t}(r_t);$\\

\vspace{3 mm}
\noindent
END 
$$
\end{equation}

\newpage

\textbf{\underline{Monte Carlo Simulations with the Baseline NKPC}}\\

\vspace{5 mm}

\small{\textbf{\underline{DGP:}}}\\

$$
\begin{cases} 
x_t = E_t x_{t+1}  -\frac{1}{\tau}(r_t - E_t \pi_{t+1})+ \epsilon_{x,t} \\
\pi_t = \beta E_t \pi_{t+1} + \gamma x_t + \epsilon_{\pi,t} \\
r_t = max\{ 0, \rho r_{t-1} +(1-\rho) (\phi_x x_t + \phi_{\pi} \pi_t) + \eta_{r,t}\} \\
\epsilon_{y,t} = \rho_y \epsilon_{y,t-1} + \eta_{y,t} \\ 
\epsilon_{\pi,t} = \rho_{\pi} \epsilon_{\pi,t-1} + \eta_{\pi,t} \\
\end{cases} 
$$

\noindent
Parameters in normal regime: $ \gamma=0.01, \tau=3, \phi_x = 0.5, \phi_{\pi}= 1.5, \rho_x=0.5, \rho_{\pi}=0.5, \rho_r = 0.9, \eta_x=0.7, \eta_r=0.3,\eta_{\pi}=0.3$ \\
Parameters in ZLB regime: $ \phi_x = 0, \phi_{\pi} = 0, \rho_r = 0 , \eta_{\pi}=0.03$\\



\small{\textbf{\underline{Accuracy Rates:}}}\\

\noindent
Normalized absolute mean error (NAME): $\frac{\frac{\sum_{t=1}^N |x_t -\hat{x}_t | }{N}}{max(x_t)-min(x_t)}$. \\
Normalized root mean squared error (NRMSE): $\frac{\sqrt{\frac{\sum_{t=1}^N (x_t - \hat{x}_t )^2}{N}}}{max(x_t)-min(x_t)}$.\\

\begin{table}[H]


\begin{tabular}{l|ll|ll}

state & Correct Init. & & Random Init.  \\
& NAME & NRMSE & NAME & NRMSE\\
\hline
$\epsilon_y$ & .9992 & 	.9987 & .9751 & .9560 \\
$\epsilon_{\pi}$ & 1 & 1 & .9594 & .9243 \\
$\alpha_y$ & .9989 & .9985 & .9299 & 8878 \\
$\beta_y$ & .9979 & .9965 & .9623 & .9065  \\
$\alpha_{\pi}$ & 1 & 1 & .8281 & .7231 \\
$\beta_{\pi}$ & .9999 & .9999 & .9372 & .8638 \\
s & .9207 & -& .8961 & - \\


\end{tabular}
\end{table}

\newpage

\begin{figure}[H]

\small{\textbf{Plots from a typical simulation with correctly specified initial states \& beliefs:}}\\
\small{\textbf{(Filtered and actual beliefs, states and state probabilities.)}}\\

\includegraphics[scale=0.45]{MC_correctInit_beliefs.pdf} 
\includegraphics[scale=0.45]{MC_correctInit_states.pdf} \\
\includegraphics[scale=0.9]{MC_correctInit_stateProbabilities.pdf}\\
\end{figure}



\begin{figure}[H]
\small{\textbf{Plots from a typical simulation with randomized  initial states \& beliefs:}}\\

\includegraphics[scale=0.45]{MC_randomInit_beliefs.pdf} 
\includegraphics[scale=0.45]{MC_randomInit_states.pdf} \\
\includegraphics[scale=0.9]{MC_randomInit_stateProbabilities.pdf}\\

\end{figure}
\newpage

\textbf{\underline{Filtering with real data: ($1966:I-2016:IV$ U.S)}}\\

\begin{figure}[H]

{Decreasing gain learning:}  \\


\includegraphics[]{NKPC_filteredRegimes_DGL.pdf}\\
\includegraphics[]{NKPC_filteredBeliefs_DGL.pdf}\\
\end{figure}

\newpage

\begin{figure}[H]
	{Constant gain learning $ =0.05$:} \\


\includegraphics[]{NKPC_filteredRegimes_CGL.pdf}\\
\includegraphics[]{NKPC_filteredBeliefs_CGL.pdf}\\
\end{figure}


\newpage



\begin{figure}
\textbf{\underline{Simulations of the Normal and \& ZLB Regimes:}} \\


{Normal Regime is E-stable:} \\

\includegraphics[scale=1]{simulation_normalRegime.pdf} \\

{ZLB Regime is not E-stable: } \\

\includegraphics[scale=1]{simulation_zlbRegime.pdf}\\
\end{figure}




\subsection*{Markov Switching Filter with two lags}

\begin{figure}[H]
\includegraphics[]{MC_MS_small_states.pdf}\\

\end{figure}


\begin{figure}[H]
\includegraphics[scale=0.5]{MC_MS_small_regime1.pdf}
\includegraphics[scale=0.5]{MC_MS_small_regime2.pdf}\\

\end{figure}

\newpage

\end{comment}

\subsection*{Example 1:Fisherian Model of Inflation Determination}

To set the ideas, consider first the Fisherian model of inflation determination:

$$
\begin{cases}
i_t = E_t \pi_{t+1} + r_t \\
r_t = \rho r_{t-1} + v_t \\
i_t = \alpha(s_t) \pi_t \\
\end{cases}
$$

where $ r_t $ is the exogenous AR(1) ex-ante real interest rate, $ i_t $ is the nominal interest rate and $\pi_t $ is inflation. Monetary policy follows a simple rule by adjusting nominal interest rate to inflation and changes stochastically between two regimes, with $s_t = \{1,2 \} $ and transition matrix:

$$
Q=\begin{pmatrix}
p_{11} & 1-p_{11} \\
1-p_{22} & p_{22} \\
\end{pmatrix}
$$

We can re-write the model in terms of inflation as follows: \\

$$
\begin{cases}
\pi_t = \frac{1}{\alpha(s_t)}(E_t \pi_{t+1} + r_t) \\
r_t = \rho r_{t-1} + v_t \\
\end{cases}
$$

When expectations are regime=dependent, the MSV-solution is of the form: $ \pi_{i,t} = \beta_i r_t $ (Davig \& Leeper, 2005). In this case, the model will be determinate as long as :\\

$$ (1-\alpha_2) p_{11} +(1-\alpha_1) p_{22} + \alpha_1 \alpha_2 > 1 $$. 

Based on Davig \& Leeper (2006), this is known as the long-run Taylor principle.\\
 

In this paper, we deviate from previous literature by assuming a regime-independent PLM of the form: \\

$$
\pi_t = a r_t  \Rightarrow E_t \pi_{t+1} = \beta E_t r_{t+1} = a \rho r_t 
$$

The implied ALM is then given by: \\

$$
\begin{cases}
\pi_t = \frac{1}{\alpha(s_t)} (\beta \rho + 1) r_t \\
r_t= \rho r_{t-1} + v_t 
\end{cases}
$$ 

Since the assumed PLM does not nest the regime-specific MSV solution, it can never converge to the underlying Rational Expectations Equilibrium. However, there is a non-rational equilibrium associated with the above PLM; this is commonly known as a Restricted Perceptions Equilibrium (RPE) in the adaptive learning literature. The value of $\beta$ corresponding to this RPE is pinned down by unconditional moment restrictions. Accordingly, $\frac{E [\pi_t r_t]}{E[r_t r_t]} $ should match in implied ALM and PLM\footnote{In principle, we can use any other moment restrictions to pin down the value of $\beta$. We use this moment since it yields the least complicated expressions.}. \\

-In PLM, we have: $\frac{E [\pi_t r_t]}{E[r_t r_t]} =\beta $.\\

-In implied ALM, we have: $\frac{ E[\pi_t r_t]}{E[r_t r_t]} = E[ \frac{1}{\alpha(s_t)} \beta \rho + \frac{1}{\alpha(s_t)}]$.

The unconditional moment in implied ALM above requires the ergodic distribution of the Markov chain: $ \pi' Q = \pi $. \\

We get $ \pi = [ \frac{1-p_{22}}{2-p_{11}- p_{22}}, \frac{1-p_{11}}{2-p_{11}-p_{22}}] $. \\

This yields $ \beta = \frac{1}{\sum_i \pi_i \alpha_i  -\rho } $, and the solution reduces to: \\

$$ \pi_t = \frac{1}{\sum_i \pi_i \alpha_i  -\rho} r_t $$

\newpage

\underline{E-stability} \\

The mapping from agents' PLM to the implied ALM is defined as the T-map. In our example, this mapping is given by: \\

$$ T: a \rightarrow \frac{\beta \rho + 1 }{\sum_i \pi_i \alpha_i} $$

The T-map is locally stable if its Jacobian matrix has eigenvalues with real parts less than one. When this local stability condition is satisfied, the equilibrium is said to be E-stable (Evans \& Honkapohja, 2001). In our example, the Jacobian is given by: \\

$$ \frac{DT(\beta)}{D(\beta)} = \frac{\rho}{\sum_i \pi_i \alpha_i} $$. 

Hence the equilibrium is E-stable if the largest eigenvalue has real part less than one, i.e. $\frac{\rho}{\sum_i \pi_i \alpha_i} < 1 $. \\

With two regimes and $\alpha_2 = 0 $, the E-stability condition reduces to : \\

$$ \alpha_1 > \frac{\rho}{\pi_1} $$


In general, in order to satisfy E-stability, we need a stronger monetary policy rule $\alpha_1 $ whenever: \\

\noindent
-The average time spent in regime 1 ($\pi_1 $) decreases, \\
-The average time spent in regime 2 ($\pi_2 $) increases, \\
-The monetary policy rule in regime 2 ($\alpha_2 $) weakens.\\

\noindent
Intuitively, this result is a simple extension of the long-run Taylor principle of David \& Leeper (2005). (Maybe we shall call this the long-run E-stability principle??) \\


\newpage

\underline{Simulations with least squares updating:}\\

$$
\begin{cases}

For the model under consideration, the baseline recursive least squares updating (Evans \& Honkapohja, 2001) is given as follows: \\

R_t = R_{t-1} + \gamma (r_t^2 - R_{t-1} ) \\
\beta_t = \beta_{t-1} + \gamma R_t^{-1} r_t (\pi_t - \beta_{t-1} r_t) 
\end{cases}
$$

Parameters: $\rho = 0.9, p_{11}=0.95, p_{22}= 0.95, \eta_{\sigma} = 0.1, \gamma=0.001 $, where $\gamma $ denotes the gain parameter. \\

For our simulations, we consider two scenarios: \\

Case (i) Both underlying regimes are E-stable: $ \alpha_1 = 2, \alpha_2 = 1.5 $. \\
In this case the coefficient fluctuates between the regime-specific equilibrium values depending on which regime is realized. On average, it fluctuates around the long-run (or unconditional) equilibrium value. \\

Case (ii) One E-stable and one E-unstable : $ \alpha_1 = 2, \alpha_2 = 0.5 $. \\
In this case the coefficient will show explosive-like dynamics (does this relate to escape dynamics?) when the realized regime is E-unstable, but will revert back to the long-run equilibrium when the system switches back to the E-stable regime. 

\begin{figure}[H]
\caption{Left panel: Case (i) with two E-stable regimes. Right panel: Case (ii) with one E-stable and one E-unstable regime. }
\includegraphics[scale=0.6]{fisher_simulation1_learningCoef.pdf} 
\includegraphics[scale=0.6]{fisher_simulation2_learningCoef.pdf} \\
%\includegraphics[scale=0.6]{fisher_simulation1_FE.pdf} \\
\includegraphics[scale=0.6]{fisher_simulation1_pinf.pdf} 
\includegraphics[scale=0.6]{fisher_simulation2_pinf.pdf} \\
\end{figure}



\newpage

\subsection*{Example 2: 3-equation model without lagged endogenous variables} 

Now consider the baseline 3-equation NKPC model along the lines of Woodford (2003), where the interest rate is subject to the ZLB constraint. This example extends the results of the previous one to the multi-dimensional case, where we can still analytically compute the underlying Restricted Perceptions Equilibrium in the absence of lagged endogenous variables.\\

$$
\begin{cases} 
x_t = E_t x_{t+1}  -\frac{1}{\tau}(r_t - E_t \pi_{t+1})+ \epsilon_{x,t} \\
\pi_t = \beta E_t \pi_{t+1} + \kappa x_t + \epsilon_{\pi,t} \\
r_t = max\{ 0, \phi_x x_t + \phi_{\pi} \pi_t + \eta_{r,t}\} \\
\epsilon_{y,t} = \rho_y \epsilon_{y,t-1} + \eta_{y,t} \\ 
\epsilon_{\pi,t} = \rho_{\pi} \epsilon_{\pi,t-1} + \eta_{\pi,t} \\
\end{cases} 
$$

We can re-cast the interest rate rule above as a Markov process with two regimes, where: \\

$$
\begin{cases}
r_t (s_t=1) = \rho r_{t-1} +(1-\rho) (\phi_x x_t + \phi_{\pi} \pi_t) + \eta^{1}_{r,t}\} 
r_t (s_t=2) =\eta^{2}_{r,t}\} 
\end{cases}
$$

with the transition matrix same as in the first example. The presence of noise in the second regime is meant to capture the fact that, although interest rates are very close to zero in empirical data, they are never exactly equal to zero in the post-2007 period. The above model can then be re-written as follows: \\

$$
\begin{cases}
X_t = C(s_t) E_t X_{t+1} + D(s_t) \epsilon_t \\
\epsilon_t = \rho \epsilon_{t-1} + \eta_t \\
\end{cases}
$$

The regime-independent PLM and one-step ahead expectations are given by: \\

 $ X_t = d \epsilon_t \Rightarrow E_t X_{t+1} = d \rho \epsilon_t $.\\

which yields the implied ALM:\\

$$
\begin{cases}
X_t = C(s_t) d \rho \epsilon_t+ D(s_t) \epsilon_t \\
\epsilon_t = \rho \epsilon_{t-1} + \eta_t \\
\end{cases}
$$

Imposing the following moment restriction for consistency yields: \\

$ \frac{ E[X_t \epsilon_t]}{E[\epsilon_t \epsilon_t]}= d  $  in PLM; this should be equal the the corresponding unconditional moment in ALM. Solving yields: \\

$ d = \sum_i C_i \pi_i d \rho + \sum_i \pi_i D_i $. \\

Hence 
$$ vec(d) = (I-\rho \otimes (\sum_i C_i))^{-1} vec(\sum_i \pi_i D_i ) $$

In this case the T-map is given by : \\

$$ T : d \rightarrow \sum_i \pi_i C_i d \rho + \sum_i D_i \pi_i $$

with Jacobian matrix  $ \frac{DT }{D d} = vec^{-1}(\rho' \otimes \sum_i \pi_i C_i) $. If all eigenvalues of this expression have real parts less than one, then the equilibrium is locally stable under least squares learning. 

\newpage 

\textbf{Monte Carlo Simulations: } \\

Parameters: $\phi_y =0.5, \phi_{\pi}=1.5, \kappa=0.01, \beta=0.99, \sigma_y = 0.7, \sigma_{\pi} =0.3, \sigma^{I}_r =0.3, \sigma^{II}_r=0.01,\rho_y =0.5, \rho_{\pi}=0.5 , p_{11} = 0.99, p_{22} = 0.9, \gamma = 0.01$. In each case, we simulate the model 500 times with a length of 10000 periods. We then collect the final values of learning coefficients in PLM. \\


\begin{figure}[H]
\caption{Case (i): Least squares updating in NKPC without regime-switching: This is the standard adaptive learning case, which illustrates what we kind of distributions we should expect from the Monte Carlo experiment in the absence of Markov-switching. First row: intercept terms (should converge to zero). Second \& third rows: lagged inflation and output gap (should converge to zero). Fourth \& fifth rows: coefficients on output gap and inflation shocks (should be non-zero). The red lines correspond to the underlying REE.  }

\includegraphics[scale=1.2]{MC_MSV_withoutLags.pdf}\\
\end{figure}

\newpage



\begin{figure}[H]
\caption{ Case (ii): Least squares updating NKPC with two regimes as outlined above.   First row: Intercept terms (should converge to zero). Second \& third rows: coefficients on output gap and inflation shocks (these should be non-zero). The coefficients on shocks should converge to the RPE as given above; these values are again denoted by the red lines. For these simulations, we do not include the lagged inflation and output gap in PLM (If they are included, they should converge to zeros similar to the case above). } 

\includegraphics[scale=0.6]{MC_MS_MSV_withoutLags.pdf}\\
\end{figure}



\begin{figure}[H]
\caption{Typical simulation from Markov-switching exercise above: Convergence toward the underlying RPE.} 
\textbf{Intercept terms:} \\
\includegraphics[scale=0.4]{MS_simulation_alphas.pdf}\\
\textbf{Shock coefficient terms: } \\
\includegraphics[scale=0.4]{MS_simulation_shockCoef.pdf}\\
\end{figure}

\subsection*{General Case I : MSV learning} 

In the above examples considered, lagged state variables do not enter into the model. In these cases, the underlying RPE takes a simple form that can be computed analytically. However, in empirically relevant models, lagged state variables typically enter into the model equation (via habit formation, price / wage indexation, interest rate smoothing, etc.). In this section we consider MSV-learning where the lagged state variables are included in the model. Consider the model of the form: \\

$$
\begin{cases}
X_t = A(s_t) + B(s_t) X_{t-1} + C(s_t) E_t X_{t+1} + D(s_t) \epsilon_t \\
\epsilon_t = \rho \epsilon_{t-1} + \eta_t 
\end{cases}
$$

PLM takes the form of MSV solution but is regime-independent, which is given by (along with the one-step ahead expectations) : \\

$$
\begin{cases}
X_t = a + b X_{t-1} + d \epsilon_t \\
E_t X_{t+1} = (a+ba) + b^2 X_{t-1} + (bd + d\rho) \epsilon_t 
\end{cases}
$$
which yields the implied ALM: \\

$$
X_t = ( A(s_t) + C(s_t) (a+ba) ) + (C(s_t) b^2 + B(s_t))X_{t-1} + ( C(s_t) (bd +d \rho ) + D(s_t) ) \epsilon_t 
$$

For the remainder, we use the notation $\tilde{m} = \sum_i \pi_i m_i $ for the weighted average of any matrices $m_i $. Imposing the moment restrictions in this case yields: \\

$$
\begin{cases}
a = E[ A(s_t) + C(s_t)  (a+ba)]= \tilde{A} + \tilde{C} (a+ba) \\
b=E[C(s_t) b^2 + B(s_t)]=\tilde{C} b^2 + \tilde{B} \\
d = E[C(s_t) (bd+d \rho) + D(s_t)] = \tilde{C} (bd + d \rho ) + \tilde{D} 
\end{cases}
$$

In the above expression, $ a $ and $ d $ can be obtained for a given b. However, the second equation is quadratic in b. With $n $ endogenous variables, this can in principle have up to $ {2n}\choose{n} $ solutions in $b$ (Check this!). \\

In this case, the T-map is given by: \\

$$
\begin{pmatrix} a \\ b \\ d \end{pmatrix} \rightarrow \begin{pmatrix} \tilde{A} + \tilde{C} (a+ba) \\ \tilde{C} b^2 + \tilde{B} \\  \tilde{C} (bd+d \rho) + \tilde{D} \end{pmatrix}
$$

Denoting $\theta = (a,b,d)' $, the associated Jacobian is : \\

$$ \frac{ D T } { D\theta }  = \begin{bmatrix} \tilde{C} + \tilde{C} b & vec_{n,n}^{-1} (a' \otimes \tilde{C}) & 0 \\
0 & 2 \tilde{C} b & 0 \\
0 & vec_{n,n}^{-1}(d' \otimes \tilde{C} ) & \tilde{C} b + vec_{n,n}^{-1} (\rho' \otimes \tilde{C} ) \end{bmatrix} $$

where $ vec_{n,n}^{-1} $ denotes the matricization of a vector to an $(n,n) $ matrix. \\

The eigenvalues of the Jacobian above are given by the terms on the diagonal. Hence the underlying RPE is E-stable if these eigenvalues have real parts less than one. \\

(these eigenvalues include the $ b $ term itself, i.e. $b $ will converge to something if $b $ satisfies a certain condition. Does this make sense? Cars' paper had something similar and the referees didn't like it, is it the same thing? ) \\

Although we cannot obtain an explicit expression for the underlying equilibrium, we can still simulate the model and check whether the coefficients converge somewhere. The figure below provides the same exercise as in the previous section, where we add an interest rate smoothing coefficient of $0.9$ to the interest rate rule in the first regime.



\begin{figure}[H]
\caption{Distributions from 500 simulations of length 10000 for the two-regime NKPC. First row: intercept terms (should converge to zero). Second and third rows: lagged inflation and output gap coefficients (should converge to zero as they do not belong in the MSV-rule). Fourth row: Lagged interest rate: should converge to non-zero values given non-zero interest rate smoothing. Fifth and sixth rows: Coefficients on output gap and inflation shocks: should converge to non-zero values. Overall, we observe similar distributions compared to the switching (and also non-switching) case of previous section, indicating convergence towards an equilibrium. }
\includegraphics[scale=1]{MC_MS_MSV_withLags.pdf}\\
\end{figure}


\newpage


\subsection*{General Case II: VAR(1) learning} 

So far we considered MSV-type of learning, where the only source of misspecification in PLM comes from the fact that expectations are not regime-specific. In general, however, we can consider any type of misspecification in the PLM and there may exist an E-stable RPE associated with the given PLM. In this section, we extend our analysis to VAR(1)-type rules with unobserved shocks. 
Accordingly, consider again models of the form:

$$
\begin{cases}
X_t = A(s_t) + B(s_t) X_{t-1} + C(s_t) E_t X_{t+1} + D(s_t) \epsilon_t \\
\epsilon_t = \rho \epsilon_{t-1} + \eta_t 
\end{cases}
$$

Since shocks are assumed to be unobserved, we can stack up the endogenous variables $X_t $ and exogenous shocks $\epsilon_t $ into a vector $ S_t = [X_t' \hspace{3 mm}\epsilon_t']' $ to obtain models of the form: \\

$$
S_t = \gamma_0 (s_t) + \gamma_1 (s_t) S_{t-1} + \gamma_2(s_t) E_t S_{t+1}  + \gamma_3 (s_t) \eta_t
$$

Assume the PLM, and the one-step ahead expectations take the form: \\

$$
\begin{cases}
S_t = a + b S_{t-1} + u_t \\
E_t S_{t+1} = (a+ba)+ b^2 S_{t-1} 
\end{cases}
$$

Implied ALM is given by: \\

$$ 
S_t = (\gamma_0 (s_t) + \gamma_2 (s_t) (a+ba))+ (\gamma_1 (s_t) +\gamma_2 (s_t) b^2 )S_{t-1} + \gamma_3(s_t) \eta_t 
$$

In cases where the matrix $b $ does not exactly coincide with the functional form of the MSV solution, the consistency requirements do not simplify. \\

$ E [ S_t ] = (I-b)^{-1} a  $ in PLM.  \\

$ E [S_t] = ( I -  \tilde{\gamma_1} - \tilde{\gamma_2} b^2 )^{-1} (\tilde{\gamma_0} + \tilde{\gamma_2}(a+ba)  ) $ in ALM. \\

The vector $ a $ in the expression above can be solved for a given $ b $. Next we turn to the consistency requirement for the matrix $ b $. Note that in PLM, we have : \\

$ E [ \tilde{S_t} \tilde{S_t}']^{-1} E [ \tilde{S_t} \tilde{S_{t-1}}'] = b $, where $\tilde{S_t} = S_t - E[S_t]$. Hence we turn to computing these moments in ALM. Denoting by $\Gamma_0 $ and $\Gamma_1 $ the variance and autocovariance matrices respectively, the first two Yule-Walker equations of the ALM are given as : \\

$$
\begin{cases}
\Gamma_1 = \tilde{M}(b) \Gamma_0 \\
\Gamma_0 = \tilde{M}(b) \Gamma_0 \tilde{M}(b)' + \tilde{\gamma_3}\Sigma_{\eta} \tilde{\gamma_3}' 
\end{cases}
$$

where $\tilde{M}(b) = \tilde{\gamma_1} + \tilde{\gamma_2} b^2$. Solving the second expression above yields 
$$ vec(\Gamma_0) = (I- \tilde{M}(b) \otimes \tilde{M}(b))^{-1} (\tilde{\gamma_3} \otimes \tilde{\gamma_3}) vec(\Sigma_{\eta}) $$

Hence for each term $b(i,j) $, we have $ b(i,j) = \frac{vec(\Gamma_1)_{(j-1)N+j}}{vec(\Gamma_0)_{(j-1)N+j}} \Rightarrow b = \Gamma_1 \oslash \Gamma_0 $. \\

In the special case where $ b $ takes the form of the corresponding MSV matrix on lagged endogenous terms, the solution for $ b $ reduces to the quadratic equation $ b = \tilde{\gamma_1 } + \tilde{\gamma_2 } b^2 $ as in the previous case. \\

The T-map in this case is given by the following: \\

$$
T: \begin{pmatrix} a \\ b \end{pmatrix}  \rightarrow \begin{pmatrix} \tilde{\gamma_0} + \tilde{\gamma_2} (a+ba) \\ \tilde{\gamma_1} + \tilde{\gamma_2} b^2 \end{pmatrix} 
$$

Denoting $ \theta = (a,b) $ , the corresponding Jacobian is \\

$$
\frac{DT}{ D \theta} = \begin{bmatrix}  \tilde{\gamma_2 } (I+b) & vec^{-1}_{n,n} ( a' \otimes \tilde{\gamma_2}) \\ 0 & 2 b \tilde{\gamma_2}  \end{bmatrix} 
$$
Hence the corresponding RPE will be E-stable if the eigenvalues $\tilde{\gamma_2} (I+b) $ and $ 2 b \tilde{\gamma_2} $ have real parts less than one. \\

\section*{Bayesian Estimation of Markov-Switching DSGE Models under Adaptive Learning: Filtering Algorithm }

We extend Kim \& Nelson (1999) algorithm with least squares updating for expectations. In Markov-switching models with $ m $ regimes, there are $ m^t $ different timelines at each period $t$, which quickly make the standard Kalman filter algorithm intractable. The standard way of dealing with this issue is to "collapse" the state variables and covariance matrices at each iteration to reduce the number of timelines. In our approach, we carry only a single lag of the state variables. This means, if there are $ m $ regimes in the model, we carry $ m $ different timelines in each period. There are $ m^2 $ different sets of variables in the forecasting and updating steps of each iteration. These are collapse at the end of each iteration to reduce to $ m $ sets of variables. In order to introduce adaptive learning into this framework, we further collapse the $ m $ sets of variables into a single vector based on the filtered probabilities. This gives us the filtered states at each iteration. The expectations are then updated once, based on the single set of filtered states. These expectations are then used in each timeline in the following iterations. See Kim \& Nelson (1999) for the details of Kalman and Hamilton Filter blocks.\\


State-space representation of the model, where $S_t $ and $y_t $ denote (unobserved) states and observable variables respectively: \\

$$
\begin{cases}
S_t = \gamma_2 + \gamma_1 S_{t-1} + \gamma_3 \epsilon_t, \hspace{3 mm}, \epsilon_t \sim N(0, \sigma) \\
y_t = E+ F S_t \\
\end{cases}
$$

\noindent
\underline{0) Initial  States :}

$ \tilde{S}_{0|0}^{i}, \tilde{P}_{0|0}^{i}, Pr[ S_0=i | \Phi_0] , \Phi_0$  given.\\
\vspace{6 mm}


\noindent
\underline{1) Kalman Filter Block with the standard measurement and transition equations:} \\
\vspace{6 mm}
For $t=1:N$
    For $\{S_{t-1}=i, S_t=j\} $
\noindent
$$
\begin{cases}
S_{t|t-1}^{(i,j)}=\gamma_1^{(j)} S_{t-1|t-1}^{(i)} + \gamma_2^{(j)} \\
P_{t|t-1}^{(i,j)}=\gamma_1^{(j)} P_{t-1|t-1}^{(i)} \gamma_1^{(j)} + \gamma_3^{(j)} \Sigma^{(j)} (\gamma_3^{(j)})^{\prime} \\
v^{(i,j)}_{t|t-1} = (y_t - F^{(j)} S_{t|t-1}^{(i,j)})\\
Fe^{(i,j)}=F^{(j)} P_{t|t-1}^{(i,j)}F^{(j)} \\
S_{t|t}^{(i,j)}= S_{t|t-1}^{(i,j)} + P_{t|t-1}^{(i,j)} (F^{(j)})^{\prime} {(Fe^{(i,j)})}^{-1} v^{(i,j)} \\
P_{t|t}^{(i,j)} = P_{t|t-1}^{(i,j)} (F^{(j)})^{\prime} (Fe^{(i,j)})^{-1} F^{(j)} P_{t|t-1}^{(i,j)} \\
\end{cases}
$$

\vspace{10 mm}

\noindent
\underline{2)  Hamilton Block for transition probabilities:}\ \\
\vspace{6 mm}

\noindent
Denote: \\

 $ Pr[S_{t-1}=i,S_t=j | \Phi_{t-1} ] = pp_{t|t-1}^{i,j} $,\\
$f(y_t|\Phi_{t-1}) $, \\
$Pr[S_{t-1}=i,S_t=j|\Phi_t]= pp_{t|t}^{i,j} $, \\
$Pr[S_t=j|\Phi_t]= \tilde{pp_{t|t}^{j}}$ \\
\vspace{5 mm}

$$
\begin{cases}
pp_{t|t-1}^{(i,j)}=Q(i,j) pp_{t-1|t-1}^{(i)} \\
f(y_t|\Phi_{t-1}) = \sum_{j=1}^M \sum_{i=1}^M f(y_t | S_{t-1}=i, S_t=j, \Phi_{t-1} ) pp_{t|t-1}^{(i,j)} \\
pp_{t|t}^{(i,j)} = \frac{f(y_t | S_{t-1} = i, S_t = j, \Phi_{t-1}) pp_{t|t-1}^{(i,j)} } { f(y_t| \Phi_{t-1})} \\
p_{t|t}^{j} = \sum_{i}^M pp_{t|t-1}^{(i,j)}\\
\end{cases}
$$


\noindent
\underline{3) Collapsing to reduce the number of states from $m^2 $ to m:} \\
$$
\begin{cases}
{S}_{t|t}^{(i)} = \frac{\sum_{i=1}^M pp_{t|t}^{(i,j)} S_{t|t}^{(i,j)} } { p_{t|t}^{(j)}} \\
{P}_{t|t}^{(i)}= \frac{\sum_{i=1}^M pp_{tt}^{(i,j)} (P_{t|t}^{(i,j)} + (S_{t|t}^{(j)} - S_{t|t}^{(i,j)})(S_{t|t}^{(j)} - S_{t|t}^{(i,j)})^{\prime})}{p_{t|t}^{(j)}}
\end{cases}
$$
\vspace{1 mm}

\noindent
\underline{4) Update expectations based on filtered states:} \\
\vspace{5 mm}

\textbf{Filtered states:} \\

$$
\tilde{S}_{t|t} = \sum_{j=1}^M p_{t|t}^{(j)} S_{t|t}^{(j)}
$$

\textbf{Expectations: } \\

$$
\begin{cases}
\Phi_t = \Phi_{t-1} + \gamma R_t^{-1} \tilde{S}_{t-1|t-1}(\tilde{S}_{t|t}- \Phi_{t-1}^{T} \tilde{S}_{t-1|t-1})^{T} \\
R_t^{-1} = R_{t-1} + \gamma (\tilde{S}_{t-1|t-1}\tilde{S}_{t-1|t-1}^{T} - R_{t-1}) \\
\end{cases}
$$


\section*{NKPC Estimation-Monte Carlo Exercise}

Before moving onto estimation with real historical data, we first check the performance of the filter on a short simulated dataset of 200 periods based on the 3-equation NKPC model. The length of the dataset is chosen to be close to our historical dataset of the U.S data over period 1966-I:2016:IV. The red lines denote the true parameter values of the simulation, accompanied by the resulting distributions of the Metropolis-Hastings MCMC with 100000 draws. We observe small biases with the exit probability of the ZLB regime, and 
the gain parameter of the expectations updating. However, the filter performs reasonably well overall, and all other parameters have the true parameter in their estimated 90 \% HPD interval.\\

\begin{figure}[H]
\includegraphics[scale=0.5]{nkpc_mc_posteriors.pdf}\\
\end{figure}



\section*{Estimating the Baseline NKPC: REE-Based initial beliefs} 



\begin{table}[H]
\caption{Estimation Sample: 1966:I-2016:IV based on the U.S data, where the observables are the output gap (based on CBO's historical estimates), inflation and interest rate.The Markov-switching REE model is based on J. Maih's RISE toolbox, while the standard REE case is provided by Dynare. The AR(1), VAR(1) and MSV-learning cases are based on our algorithm above. }

\vspace{3 mm}

\begin{tabular}{l||lll||l|l|l|ll}
Parameter & Prior &  &  & Posterior &  &  &  &  \\
 &  &  &  & AR(1) & VAR(1) & MSV & REE-MS & REE \\
\hline
\hline
 & Dist & Mean & St. Dev & Mode & Mode & Mode & Mode & Mode  \\
$\bar{y}$ & Normal & 0 & 0.25 & -0.21 & 0.09 & -0.32 & -0.17 & 0.24 \\
$\bar{\pi}$ & Gamma & 0.62 & 0.25 & 0.53 & 0.9 & 0.7 & 0.39 & 0.17 \\
$\bar{r_1}$ & Gamma & 1 & 0.25 & 1.05 & 1.17 & 0.84 & 0.68 & 1.11 \\
$\kappa$ & Beta & 0.3 & 0.15 & 0.033 & 0.018 & 0.005 & 0.004 & 0.006 \\
$\tau$ & Gamma & 2 & 0.5 & 2.54 & 3.01 & 3.02 & 2.75 & 4.57 \\
$\phi_{\pi}$ & Gamma & 1.5 & 0.25 & 1.25 & 1.3 & 1.56 & 1.56 & 1.42 \\
$\phi_y$ & Gamma & 0.5 & 0.25 & 0.59 & 0.51 & 0.45 & 0.27 & 0.27 \\
$\rho_y$ & Beta & 0.5 & 0.2 & 0.33 & 0.48 & 0.89 & 0.92 & 0.93 \\
$\rho_{\pi}$ & Beta & 0.5 & 0.2 & 0.04 & 0.07 & 0.85 & 0.92 & 0.89 \\
$\rho_r$ & Beta & 0.5 & 0.2 & 0.96 & 0.96 & 0.9 & 0.8 & 0.8 \\
$\eta_y$ & Inv. Gamma & 0.1 & 2 & 0.77 & 0.73 & 0.1 & 0.1 & 0.1 \\
$\eta_{\pi}$ & Inv. Gamma & 0.1 & 2 & 0.26 & 0.28 & 0.03 & 0.03 & 0.04 \\
$\eta_{r_1}$ & Inv. Gamma & 0.1 & 2 & 0.32 & 0.33 & 0.32 & 0.32 & 0.3 \\
$\bar{r_2}$ & Normal & 0.1 & 0.25 & 0.04 & 0.0 & 0.03 & 0.03 & - \\
$\eta_{r_2}$ & Uniform & 0.005 & 0.05 & 0.02 & 0.02 & 0.01 & 0.01 & - \\
$1-p_{11}$ & Beta & 0.1 & 0.05 & 0.02 & 0.02 & 0.02 & 0.02 & - \\
$1-p_{22}$ & Beta & 0.3 & 0.1 & 0.1 & 0.11 & 0.13 & 0.17 & - \\
$gain$ & Gamma & 0.035 & 0.015 & 0.0392 & 0.009 & 0.0246 & - & - \\
 \hline
\hline
Laplace &  &  &  & -296.49 & -305.37 & -289.07  & -317.02 & -368.49
\end{tabular}
\end{table}

\newpage

\begin{figure}[H]
\caption{\large{\textbf{AR(1)}}}
\vspace{5 mm}

\textbf{Interest rates and regime probability:} \\

\includegraphics[scale=0.6]{NKPC_ree_init_AR1_regime.pdf}
\includegraphics[scale=0.6]{NKPC_ree_init_AR1_regimeProb.pdf}\\

\textbf{Expectation coefficients. Intercepts on the left, first-order autocorrelations on the right.}\\

\includegraphics[scale=0.6]{NKPC_ree_init_AR1_alphas.pdf}
\includegraphics[scale=0.6]{NKPC_ree_init_AR1_betas.pdf}

\end{figure}

\newpage

\begin{figure}[H]
\caption{\large{\textbf{VAR(1)}}}
\vspace{5 mm}

\textbf{Interest rates and regime probability:} \\

\includegraphics[scale=0.6]{NKPC_ree_init_VAR1_regime.pdf}
\includegraphics[scale=0.6]{NKPC_ree_init_VAR1_regimeProb.pdf}\\

\textbf{Expectation coefficient. Intercepts on the left, first-order autocorrelations on the right.}\\

\includegraphics[scale=0.6]{NKPC_ree_init_VAR1_alphas.pdf}
\includegraphics[scale=0.6]{NKPC_ree_init_VAR1_betas.pdf}


\end{figure}

\newpage

\begin{figure}[H]
\caption{\large{\textbf{MSV}}}
\vspace{5 mm}

\textbf{Interest rates and regime probability:} \\

\includegraphics[scale=0.6]{NKPC_ree_init_MSV_regime.pdf}
\includegraphics[scale=0.6]{NKPC_ree_init_MSV_regimeProb.pdf}\\

\textbf{Expectation coefficients. Intercepts on the left, first-order autocorrelations on the right}\\

\includegraphics[scale=0.6]{NKPC_ree_init_MSV_alphas.pdf}
\includegraphics[scale=0.6]{NKPC_ree_init_MSV_betas.pdf}\\

\textbf{Shock coefficients:}\\

\includegraphics[scale=0.6]{NKPC_ree_init_MSV_shockCoef.pdf}\\


\end{figure}


\begin{figure}[H]
\caption{\large{\textbf{MSV-REE }}}
\vspace{5 mm}

\textbf{Interest rates and regime probability:} \\

\includegraphics[scale=0.6]{NKPC_sigmaPoint_regime.pdf}
\includegraphics[scale=0.6]{NKPC_sigmaPoint_regimeProb.pdf}\\




\end{figure}

\newpage

\section*{Estimating the Baseline NKPC: Optimized initial beliefs} 

\begin{table}[H]
\begin{tabular}{l||lll||l|l|l|ll}
Parameter & Prior &  &  & Posterior &  &  &  &  \\
\hline
\hline
 &  &  &  & AR(1) & VAR(1) & MSV & REE-MS & REE \\
\hline
\hline
 & Dist & Mean & St. Dev & Mode & Mode & Mode & Mode & Mode  \\
$\bar{y}$ & Normal & 0 & 0.25 & -0.15 & 0.05 & -0.35 & -0.17 & 0.24 \\
$\bar{\pi}$ & Gamma & 0.62 & 0.25 & 0.49 & 0.96 & 0.69 & 0.39 & 0.17 \\
$\bar{r_1}$ & Gamma & 1 & 0.25 & 1.03 & 1.34 & 0.88 & 0.68 & 1.11 \\
$\kappa$ & Beta & 0.3 & 0.15 & 0.03 & 0.03 & 0.038 & 0.004 & 0.006 \\
$\tau$ & Gamma & 2 & 0.5 & 2.52 & 3.11 & 2.6 & 4.73 & 4.57 \\
$\phi_{\pi}$ & Gamma & 1.5 & 0.25 & 1.25 & 1.32 & 1.55 & 1.56 & 1.42 \\
$\phi_y$ & Gamma & 0.5 & 0.25 & 0.59 & 0.36 & 0.37 & 0.27 & 0.27 \\
$\rho_y$ & Beta & 0.5 & 0.2 & 0.3 & 0.39 & 0.91 & 0.92 & 0.93 \\
$\rho_{\pi}$ & Beta & 0.5 & 0.2 & 0.05 & 0.05 & 0.81 & 0.92 & 0.89 \\
$\rho_r$ & Beta & 0.5 & 0.2 & 0.95 & 0.97 & 0.89 & 0.8 & 0.8 \\
$\eta_y$ & Inv. Gamma & 0.1 & 2 & 0.76 & 0.75 & 0.09 & 0.1 & 0.1 \\
$\eta_{\pi}$ & Inv. Gamma & 0.1 & 2 & 0.26 & 0.26 & 0.04 & 0.03 & 0.04 \\
$\eta_{r_1}$ & Inv. Gamma & 0.1 & 2 & 0.32 & 0.33 & 0.32 & 0.32 & 0.3 \\
$\bar{r_2}$ & Normal & 0 & 0.25 & 0.04 & 0.04 & 0.03 & 0.03 & - \\
$\eta_{r_2}$ & Inv. Gamma & 0.01 & 0.2 & 0.02 & 0.02 & 0.01 & 0.01 & - \\
$1-p_{11}$ & Beta & 0.1 & 0.05 & 0.02 & 0.02 & 0.02 & 0.02 & - \\
$1-p_{22}$ & Beta & 0.3 & 0.1 & 0.1 & 0.1 & 0.13 & 0.17 & - \\
$gain$ & Gamma & 0.035 & 0.015 & 0.04 & 0.0382 & 0.0085 & - & - \\
\hline
\hline
Laplace &  &  &  & -294.123 & -308.92 & -282.62 & -317.02 & -368.49
\end{tabular}
\end{table}

\begin{figure}[H]
\caption{\large{\textbf{AR(1)}}}
\vspace{5 mm}

\textbf{Interest rates and regime probability:} \\

\includegraphics[scale=0.6]{NKPC_optim_init_AR1_regime.pdf}
\includegraphics[scale=0.6]{NKPC_optim_init_AR1_regimeProb.pdf}\\

\textbf{Expectation coefficients. Intercepts on the left, first-order autocorrelations on the right.}\\

\includegraphics[scale=0.6]{NKPC_optim_init_AR1_alphas.pdf}
\includegraphics[scale=0.6]{NKPC_optim_init_AR1_betas.pdf}


\end{figure}

\newpage

\begin{figure}[H]
\caption{\large{\textbf{VAR(1)}}}
\vspace{5 mm}

\textbf{Interest rates and regime probability:} \\

\includegraphics[scale=0.6]{NKPC_optim_init_VAR1_regime.pdf}
\includegraphics[scale=0.6]{NKPC_optim_init_VAR1_regimeProb.pdf}\\

\textbf{Expectation coefficient. Intercepts on the left, first-order autocorrelations on the right.}\\

\includegraphics[scale=0.6]{NKPC_optim_init_VAR1_alphas.pdf}
\includegraphics[scale=0.6]{NKPC_optim_init_VAR1_betas.pdf}


\end{figure}

\newpage

\begin{figure}[H]
\caption{\large{\textbf{MSV}}}
\vspace{5 mm}

\textbf{Interest rates and regime probability:} \\

\includegraphics[scale=0.6]{NKPC_optim_init_MSV_regime.pdf}
\includegraphics[scale=0.6]{NKPC_optim_init_MSV_regimeProb.pdf}\\

\textbf{Expectation coefficients. Intercepts on the left, first-order autocorrelations on the right}\\

\includegraphics[scale=0.6]{NKPC_optim_init_MSV_alphas.pdf}
\includegraphics[scale=0.6]{NKPC_optim_init_MSV_betas.pdf}\\

\textbf{Shock coefficients:}\\

\includegraphics[scale=0.6]{NKPC_optim_init_MSV_shockCoef.pdf}\\


\end{figure}


\section*{Estimating the Baseline NKPC: Filter-based initial beliefs} 



\begin{table}[H]
\begin{tabular}{l||lll||l|l|l|ll}
Parameter & Prior &  &  & Posterior &  &  &  &  \\
\hline
\hline
 &  &  &  & AR(1) & VAR(1) & MSV & REE-MS & REE \\
\hline
\hline
 & Dist & Mean & St. Dev & Mode & Mode & Mode & Mode &  \\
$\bar{y}$ & Normal & 0 & 0.25 & -0.16 & -0.01 & -0.26 & -0.17 & 0.24 \\
$\bar{\pi}$ & Gamma & 0.62 & 0.25 & 0.47 & 0.46 & 0.54 & 0.39 & 0.17 \\
$\bar{r_1}$ & Gamma & 1 & 0.25 & 0.99 & 1.03 & 0.86 & 0.68 & 1.11 \\
$\kappa$ & Beta & 0.3 & 0.15 & 0.03 & 0.0081 & 0.006 & 0.004 & 0.006 \\
$\tau$ & Gamma & 2 & 0.5 & 2.51 & 2.92 & 2.79 & 4.73 & 4.57 \\
$\phi_{\pi}$ & Gamma & 1.5 & 0.25 & 1.25 & 1.26 & 1.52 & 1.56 & 1.42 \\
$\phi_y$ & Gamma & 0.5 & 0.25 & 0.59 & 0.56 & 0.33 & 0.27 & 0.27 \\
$\rho_y$ & Beta & 0.5 & 0.2 & 0.3 & 0.52 & 0.92 & 0.92 & 0.93 \\
$\rho_{\pi}$ & Beta & 0.5 & 0.2 & 0.05 & 0.09 & 0.9 & 0.92 & 0.89 \\
$\rho_r$ & Beta & 0.5 & 0.2 & 0.95 & 0.96 & 0.87 & 0.8 & 0.8 \\
$\eta_y$ & Inv. Gamma & 0.1 & 2 & 0.76 & 0.74 & 0.12 & 0.1 & 0.1 \\
$\eta_{\pi}$ & Inv. Gamma & 0.1 & 2 & 0.26 & 0.27 & 0.04 & 0.03 & 0.04 \\
$\eta_{r_1}$ & Inv. Gamma & 0.1 & 2 & 0.32 & 0.32 & 0.32 & 0.32 & 0.3 \\
$\bar{r_2}$ & Normal & 0 & 0.25 & 0.04 & 0.04 & 0.03 & 0.03 & - \\
$\eta_{r_2}$ & Inv. Gamma & 0.01 & 0.2 & 0.02 & 0.02 & 0.01 & 0.01 & - \\
$1-p_{11}$ & Beta & 0.1 & 0.05 & 0.02 & 0.02 & 0.02 & 0.02 & - \\
$1-p_{22}$ & Beta & 0.3 & 0.1 & 0.1 & 0.1 & 0.13 & 0.17 & - \\
$gain$ & Gamma & 0.035 & 0.015 & 0.0421 & 0.0064 & 0.0075 & - & - \\
 &  &  &  &  &  &  &  &  \\
Laplace &  &  &  & -294.24 & -307.34 & -290 & -317.02 & -368.49
\end{tabular}
\end{table}

\begin{figure}[H]
\caption{\large{\textbf{AR(1)}}}
\vspace{5 mm}

\textbf{Interest rates and regime probability:} \\

\includegraphics[scale=0.6]{NKPC_filter_init_AR1_regime.pdf}
\includegraphics[scale=0.6]{NKPC_filter_init_AR1_regimeProb.pdf}\\

\textbf{Expectation coefficients. Intercepts on the left, first-order autocorrelations on the right.}\\

\includegraphics[scale=0.6]{NKPC_filter_init_AR1_alphas.pdf}
\includegraphics[scale=0.6]{NKPC_filter_init_AR1_betas.pdf}


\end{figure}

\newpage

\begin{figure}[H]
\caption{\large{\textbf{VAR(1)}}}
\vspace{5 mm}

\textbf{Interest rates and regime probability:} \\

\includegraphics[scale=0.6]{NKPC_filter_init_VAR1_regime.pdf}
\includegraphics[scale=0.6]{NKPC_filter_init_VAR1_regimeProb.pdf}\\

\textbf{Expectation coefficient. Intercepts on the left, first-order autocorrelations on the right.}\\

\includegraphics[scale=0.6]{NKPC_filter_init_VAR1_alphas.pdf}
\includegraphics[scale=0.6]{NKPC_filter_init_VAR1_betas.pdf}


\end{figure}

\newpage

\begin{figure}[H]
\caption{\large{\textbf{MSV}}}
\vspace{5 mm}

\textbf{Interest rates and regime probability:} \\

\includegraphics[scale=0.6]{NKPC_filter_init_MSV_regime.pdf}
\includegraphics[scale=0.6]{NKPC_filter_init_MSV_regimeProb.pdf}\\

\textbf{Expectation coefficients. Intercepts on the left, first-order autocorrelations on the right}\\

\includegraphics[scale=0.6]{NKPC_filter_init_MSV_alphas.pdf}
\includegraphics[scale=0.6]{NKPC_filter_init_MSV_betas.pdf}\\

\textbf{Shock coefficients:}\\

\includegraphics[scale=0.6]{NKPC_filter_init_MSV_shockCoef.pdf}\\


\end{figure}


\section*{Impulse Responses (using the REE-based initial beliefs setup)}

\begin{figure}[H]
\caption{Impulse responses of time-varying PLMs are based on an arbitrary period.}
\textbf{AR(1) and VAR(1) beliefs:}\\
\includegraphics[scale=0.6]{NKPC_ree_init_AR1_IR.pdf}
\includegraphics[scale=0.6]{NKPC_ree_init_VAR_IR.pdf}\\

\textbf{MS and standard REE benchmarks: }\\

\includegraphics[scale=0.6]{NKPC_ree_init_REE_MS_IR.pdf}
\includegraphics[scale=0.6]{NKPC_ree_init_REE_IR.pdf}\\

\textbf{MSV beliefs: }\\

\includegraphics[scale=0.6]{NKPC_ree_init_MSV_IR.pdf}\\
\end{figure}

\newpage

\begin{figure}[H]
\caption{Time-varying impulse responses, final 50 periods of the estimation sample.}

\textbf{AR(1)}: \\
\includegraphics[scale=1]{NKPC_ree_init_AR1_IR_timeVarying.pdf}\\
\end{figure}

\begin{figure}[H]
\caption{Time-varying impulse responses, final 50 periods of the estimation sample.}

\textbf{VAR(1)}: \\
\includegraphics[scale=1]{NKPC_ree_init_VAR_IR_timeVarying.pdf}\\
\end{figure}

\begin{figure}[H]
\caption{Time-varying impulse responses, final 50 periods of the estimation sample.}

\textbf{MSV}: \\
\includegraphics[scale=1]{NKPC_ree_init_MSV_IR_timeVarying.pdf}\\
\end{figure}


\subsection*{SW Estimation-I}


\begin{table}[H]
\caption{Estimation period: 1966:I-2016:IV}
\begin{tabular}{llll|ll|lll}
 & Prior &  &  & AR(1) & MSV & REE & RISE &  \\
 \hline
 \hline
Param &  & Dist & Mean & Mode & Mode & Mode & Mode &  \\
\hline
\hline
$\phi$ &  & Normal & 4        		& 1.02 & 3.75 & 4.87 & 6.4 \\
$\sigma_c$ &  & Normal & 1.5		& 0.88 & 1.48 & 1.36 & 1.14 \\
$\lambda$ &  & Beta & 0.7 			& 0.55 & 0.73 & 0.75 & 0.83 \\
$\xi_w$ &  & Beta & 0.5 			& 0.7 & 0.75 & 0.93 & 0.95 \\
$\sigma_l$ &  & Normal & 2 			& 2.41 & 2.18 & 1.98 & 1.74 \\
$\xi_p$ &  & Beta & 0.5 			& 0.62 & 0.67 & 0.8 & 0.83 \\
$\iota_w$ &  & Beta & 0.5 			& 0.43 & 0.63 & 0.84 & 0.81 \\
$\iota_p$ &  & Beta & 0.5 			& 0.40 & 0.23 & 0.07 & 0.08 \\
$\psi$ &  & Beta & 0.5 				& 0.49 & 0.69 & 0.83 & 0.69 \\
$\phi_p$ &  & Normal & 1.25 		& 1.49 & 1.57 & 1.59 & 1.56 \\
$r_{\pi}$ &  & Normal & 1.25 		& 1.64 & 1.62 & 1.5 & 1.35 \\
$\rho$ &  & Beta & 0.75 			& 0.88 & 0.88 & 0.85 & 0.86 \\
$r_y$ &  & Normal & 0.125 			& 0.13 & 0.12 & 0.05 & 0.06 \\
$r_{dy}$ &  & Normal & 0.125 		& 0.14 & 0.14 & 0.17 & 0.19 \\
$\bar{\pi}$ &  & Gamma & 0.625 		& 0.71 & 0.86 & 0.75 & 0.76 \\
$\bar{\beta}$ &  & Gamma & 0.25 	& 0.14 & 0.19 & 0.21 & 0.25 \\
$\bar{l}$ &  & Normal & 0 			& 0.73 & 1.59 & -1.2 & 0.15 \\
$\bar{\gamma}$ &  & Normal & 0.4 	& 0.4 & 0.43 & 0.4 & 0.41 \\
$\alpha$ &  & Normal & 0.3 			& 0.15 & 0.16 & 0.17 & 0.18 \\
$\rho_a$ &  & Beta & 0.5 			& 0.98 & 0.95 & 0.96 & 0.95 \\
$\rho_b$ &  & Beta & 0.5 			& 0.35 & 0.42 & 0.36 & 0.29 \\
$\rho_g$ &  & Beta & 0.5 			& 0.99 & 0.99 & 0.98 & 0.98 \\
$\rho_i$ &  & Beta & 0.5 			& 0.48 & 0.83 & 0.83 & 0.76 \\
$\rho_r$ &  & Beta & 0.5 			& 0.15 & 0.07 & 0.08 & 0.16 \\
$\rho_p$ &  & Beta & 0.5 			& 0.03 & 0.64 & 0.81 & 0.78 \\
$\rho_w$ &  & Beta & 0.5 			& 0.04 & 0.19 & 0.06 & 0.05 \\
$\rho_{ga}$ &  & Beta & 0.5 		& 0.52 & 0.5 & 0.53 & 0.51 \\
$\eta_a$ &  & Inv. Gamma & 0.1 		& 0.46 & 0.43 & 0.44 & 0.45 \\
$\eta_b$ &  & Inv. Gamma & 0.1 		& 0.68 & 0.21 & 0.21 & 0.23 \\
$\eta_g$ &  & Inv. Gamma & 0.1 		& 0.48 & 0.48 & 0.49 & 0.48 \\
$\eta_i$ &  & Inv. Gamma & 0.1 		& 1.36 & 0.36 & 0.36 & 0.34 \\
$\eta_{r,N}$ &  & Inv. Gamma & 0.1 	& 0.21 & 0.21 & 0.21 & 0.23 \\
$\eta_{r,ZLB}$ &  & Gamma & 0.03 	& 0.01 & 0.01 & - & 0.01 \\
$\eta_p$ &  & Inv. Gamma & 0.1 		& 0.27 & 0.07 & 0.05 & 0.06 \\
$\eta_w$ &  & Inv. Gamma & 0.1 		& 0.73 & 0.35 & 0.37 & 0.37 \\
$gain$ &  & Gamma & 0.035 			& 0.012 & 0.001 & - &  -\\
$1-p_{11}$ &  & Beta & 0.1 			& 0.02 & 0.02 & - & 0.01 \\
$1-p_{22}$ &  & Beta & 0.1 			& 0.13 & 0.13 & - & 0.29 \\
$\bar{r_{zlb}}$ &  & Normal & 0.05 	& 0.03 & 0.03 & - & 0.03 \\
 &  &  &  &  &  &  &  \\
Laplace &  &  &  & -1135 & -1168 & -1213 & -1171
\end{tabular}
\end{table}


\subsection*{SW Estimations-II}

\begin{table}[H]
\caption{Estimation period: 1985:I-2016:IV}
\begin{tabular}{llll|ll|lll}
 & Prior &  &  & AR(1) & MSV & REE & RISE &  \\
 \hline
 \hline
Param &  & Dist & Mean & Mode & Mode & Mode & Mode &  \\
\hline
\hline
$\phi$ &  & Normal & 4 			& 0.86 & 5 & 6.72 & 4.91 &  \\
$\sigma_c$ &  & Normal & 1.5 	& 0.35 & 0.82 & 1.93 & 1.12 &  \\
$\lambda$ &  & Beta & 0.7 		& 0.6 & 0.82 & 0.7 & 0.55 &  \\
$\xi_w$ &  & Beta & 0.5 		& 0.63 & 0.69 & 0.8 & 0.84 &  \\
$\sigma_l$ &  & Normal & 2 		& 2.14 & 2.52 & 1.08 & 1.65 &  \\
$\xi_p$ &  & Beta & 0.5 		& 0.77 & 0.76 & 0.83 & 0.92 &  \\
$\iota_w$ &  & Beta & 0.5 		& 0.48 & 0.59 & 0.5 & 0.46 &  \\
$\iota_p$ &  & Beta & 0.5 		& 0.27 & 0.42 & 0.13 & 0.19 &  \\
$\psi$ &  & Beta & 0.5 			& 0.66 & 0.82 & 0.88 & 0.8 &  \\
$\phi_p$ &  & Normal & 1.25 	& 1.31 & 1.48 & 1.51 & 1.4 &  \\
$r_{\pi}$ &  & Normal & 1.25 	& 1.42 & 1.49 & 1.63 & 1.48 &  \\
$\rho$ &  & Beta & 0.75 		& 0.91 & 0.9 & 0.87 & 0.86 &  \\
$r_y$ &  & Normal & 0.125 		& 0.17 & 0.07 & 0.07 & 0.24 &  \\
$r_{dy}$ &  & Normal & 0.125 	& 0.11 & 0.07 & 0.07 & 0.09 &  \\
$\bar{\pi}$ &  & Gamma & 0.625 	& 0.68 & 0.61 & 0.67 & 0.61 &  \\
$\bar{\beta}$ &  & Gamma & 0.25 & 0.2 & 0.27 & 0.21 & 0.25 &  \\
$\bar{l}$ &  & Normal & 0 		& 3.03 & 5.69 & 1.24 & 3.82 &  \\
$\bar{\gamma}$ &  & Normal & 0.4& 0.45	 & 0.5 & 0.34 & 0.47 &  \\
$\alpha$ &  & Normal & 0.3 		& 0.11 & 0.15 & 0.17 & 0.15 &  \\
$\rho_a$ &  & Beta & 0.5 		& 0.99 & 0.99 & 0.99 & 0.98 &  \\
$\rho_b$ &  & Beta & 0.5 		& 0.60 & 0.58 & 0.34 & 0.96 &  \\
$\rho_g$ &  & Beta & 0.5 		& 0.99 & 0.99 & 0.95 & 0.98 &  \\
$\rho_i$ &  & Beta & 0.5 		& 0.40 & 0.79 & 0.85 & 0.73 &  \\
$\rho_r$ &  & Beta & 0.5 		& 0.66 & 0.52 & 0.46 & 0.48 &  \\
$\rho_p$ &  & Beta & 0.5 		& 0.03 & 0.61 & 0.55 & 0.34 &  \\
$\rho_w$ &  & Beta & 0.5 		& 0.07 & 0.19 & 0.09 & 0.09 &  \\
$\rho_{ga}$ &  & Beta & 0.5 	& 0.39 & 0.4 & 0.45 & 0.4 &  \\
$\eta_a$ &  & Inv. Gamma & 0.1 	& 0.4 & 0.38 & 0.39 & 0.05 &  \\
$\eta_b$ &  & Inv. Gamma & 0.1 	& 0.8 & 0.16 & 0.17 & 0.37 &  \\
$\eta_g$ &  & Inv. Gamma & 0.1 			& 0.38 & 0.39 & 0.4 & 0.3 &  \\
$\eta_i$ &  & Inv. Gamma & 0.1 			& 1.15 & 0.31 & 0.29 & 0.09 &  \\
$\eta_{r,N}$ &  & Inv. Gamma & 0.1 		& 0.09 & 0.08 & 0.08 & 0.09 &  \\
$\eta_{r,ZLB}$ &  & Gamma & 0.03 		& 0.01 & 0.01 & - & - &  \\
$\eta_p$ &  & Inv. Gamma & 0.1			& 0.18 & 0.07 & 0.08 & 0.11 &  \\
$\eta_w$ &  & Inv. Gamma & 0.1 			& 0.86 & 0.4 & 0.43 & 0.42 &  \\
$gain$ &  & Gamma & 0.035 				& 0.013 & 0.008 & - & - &  \\
$1-p_{11}$ &  & Beta & 0.1 				& 0.03 & 0.03 &-  & 0.01 &  \\
$1-p_{22}$ &  & Beta & 0.1 				& 0.13 & 0.13 & - & 0.28 &  \\
$\bar{r_{zlb}}$ &  & Normal & 0.05 		& 0.04 & 0.03 & - & - & - \\
 &  &  &  &  &  &  &  &  \\
Laplace &  &  &  & -515 & -566 & -583 & -552 & 
\end{tabular}
\end{table}

\subsection*{Figures-AR(1) learning (Based on Full Sample Results)}
\begin{figure}[H]
\textbf{Filtered ZLB regime probability:}\\
\includegraphics[scale=0.5]{sw_ar1_regimeProb.pdf}\\
\textbf{Eigenvalues and Projection Facility}\\
\includegraphics[scale=0.5]{sw_ar1_eigenvalues.pdf}
\end{figure}

\begin{figure}[H]
\textbf{Intercept coefficients }\\
\includegraphics[scale=0.5]{sw_ar1_learning_alphas.pdf}
\textbf{Persistence coefficients:}\\
\includegraphics[scale=0.5]{sw_ar1_learning_betas.pdf}
\end{figure}



\subsection*{Figures-MSV learning (Based on Full Sample Results)}
\begin{figure}[H]
\textbf{Filtered ZLB regime probability:}\\
\includegraphics[scale=0.5]{sw_msv_regimeProb.pdf}\\
\textbf{Projection Facility active or not:}\\
\includegraphics[scale=0.5]{sw_msv_eigenvalues.pdf}
\end{figure}

\begin{figure}[H]
\textbf{Intercept coefficients:}\\
\includegraphics[scale=0.3]{sw_msv_learning_alphas.pdf}\\
\textbf{Learning coefficient on lagged inflation:}\\
\includegraphics[scale=0.3]{sw_msv_learning_laggedInfl.pdf}\\
\textbf{Learning coefficient on  b-shock:}\\
\includegraphics[scale=0.3]{sw_msv_learning_bShock.pdf}\\
\end{figure}


\begin{figure}[H]
\textbf{In-Sample forecasts (forecasting step of the filter): MSV learning}\\
\includegraphics[height=\textheight,width=\textwidth]{sw_msv_forecast_errors.pdf}
\end{figure}

\begin{figure}[H]
\textbf{In-Sample forecasts (forecasting step of the filter): AR(1) learning}\\
\includegraphics[height=\textheight,width=\textwidth]{sw_ar1_forecast_errors.pdf}
\end{figure}

\begin{figure}[H]
\textbf{In-Sample forecasts (forecasting step of the filter): RISE }\\
\includegraphics[height=\textheight,width=\textwidth]{rise_forecast_errors.pdf}
\end{figure}

\begin{figure}[H]
\textbf{In-Sample forecasts (forecasting step of the filter): REE}\\
\includegraphics[height=\textheight,width=\textwidth]{REE_forecast_errors.pdf}
\end{figure}


\subsection*{Impulse Responses- Comparison with the REE benchmark: Normal regime and zlb impulse responses are based on 2006Q1 and 2011Q1 respectively}




\begin{figure}[H]
\caption{Comparison of AR(1) learning IRFs with RISE IRFs. One unit shocks of $\eta_a$,$\eta_b$,$\eta_g$,$\eta_i$,$\eta_p$,$\eta_w$ respectively.}
\textbf{Consumption:}\\
\includegraphics[scale=0.5]{AR1_impresp_cons_riseComp.pdf}
\textbf{Investment:}\\
\includegraphics[scale=0.5]{AR1_impresp_inv_riseComp.pdf}

\end{figure}

\begin{figure}[H]
\textbf{Output:}\\
\includegraphics[scale=0.5]{AR1_impresp_output_riseComp.pdf}
\textbf{Inflation:}\\
\includegraphics[scale=0.5]{AR1_impresp_pinf_riseComp.pdf}

\end{figure}


\begin{figure}[H]
\caption{Comparison of MSV learning IRFs with RISE IRFs. One unit shocks of $\eta_a$,$\eta_b$,$\eta_g$,$\eta_i$,$\eta_p$,$\eta_w$ respectively.}
\textbf{Consumption:}\\
\includegraphics[scale=0.5]{MSV_impresp_cons_riseComp.pdf}
\textbf{Investment:}\\
\includegraphics[scale=0.5]{MSV_impresp_inv_riseComp.pdf}

\end{figure}

\begin{figure}[H]
\textbf{Output:}\\
\includegraphics[scale=0.5]{MSV_impresp_output_riseComp.pdf}
\textbf{Inflation:}\\
\includegraphics[scale=0.5]{MSV_impresp_pinf_riseComp.pdf}

\end{figure}

\subsection*{Implied time variation in IRFs under learning: AR(1) case}

\begin{figure}[H]
\textbf{Consumption:}\\
\includegraphics[scale=0.5]{AR1_impresp_cons_3d.pdf}
\textbf{Investment:}\\
\includegraphics[scale=0.5]{AR1_impresp_inv_3d.pdf}

\end{figure}

\begin{figure}[H]
\textbf{Output:}\\
\includegraphics[scale=0.5]{AR1_impresp_output_3d.pdf}
\textbf{Inflation:}\\
\includegraphics[scale=0.5]{AR1_impresp_pinf_3d.pdf}

\end{figure}


\subsection*{Implied time variation in IRFs under learning: MSV case}

\begin{figure}[H]
\textbf{Consumption:}\\
\includegraphics[scale=0.5]{MSV_impresp_cons_3d.pdf}
\textbf{Investment:}\\
\includegraphics[scale=0.5]{MSV_impresp_inv_3d.pdf}

\end{figure}

\begin{figure}[H]
\textbf{Output:}\\
\includegraphics[scale=0.5]{MSV_impresp_output_3d.pdf}
\textbf{Inflation:}\\
\includegraphics[scale=0.5]{MSV_impresp_pinf_3d.pdf}

\end{figure}

\end{document}

